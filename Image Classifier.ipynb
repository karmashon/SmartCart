{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "94e6e511-5e5f-4336-a8b2-f14ce8bd4f2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All module imports\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "26a11bae-19ca-478f-8e31-74a4f908ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data set directory name and allowed image file extensions\n",
    "dataSetDir = \"Data Set\"\n",
    "imageExt = [\"jpg\",\"png\",\"jpeg\",\"webp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0f5854eb-fbca-4a7e-863b-f5e8d5ae4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent tensorflow from using all GPU resources\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a219b-65c6-49d9-8195-8e9daf0bf95c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# Reads all images from all directories within the dataset directory, and displays them in a pyplot\n",
    "for imageDir in os.listdir(dataSetDir):\n",
    "    for image in os.listdir(os.path.join(dataSetDir,imageDir)):\n",
    "        if image.split(\".\")[-1] in imageExt:\n",
    "            imagePath = os.path.join(dataSetDir,imageDir,image)\n",
    "            plt.imshow(cv2.cvtColor(cv2.imread(imagePath),cv2.COLOR_BGR2RGB))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "eff9f498-e4de-4c4a-a95c-aa584067e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 117 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating an image data pipeline using in-built TensorFlow functions from the nested dataset folder\n",
    "# Class labels are automatically assigned based on number of inner directories\n",
    "dataSet = tf.keras.utils.image_dataset_from_directory(dataSetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ef86e-95cc-4cbe-8d78-7bdd3d38dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numpy iterator from the dataset and splits images into batches of size 32\n",
    "# next() function retrieves the next batch of images\n",
    "iterator = dataSet.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d0e7b-504e-4399-945c-706e0e009621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# Each batch is retrieved by next() function, consisting of images in index 0, and labels in index 1.\n",
    "# Each image is displayed with its corresponding class label\n",
    "nextBatch = iterator.next()\n",
    "for index in range(len(nextBatch[1][:16])):\n",
    "    plt.imshow(nextBatch[0][index].astype(int))\n",
    "    plt.title(nextBatch[1][index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5549eaf4-7a0b-410f-9935-cf95dae579e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to fit the pixel values from 0-1 instead of 0-255\n",
    "# This is done by map() function which applies the lambda function to all data in the numpy array\n",
    "# Here, only x values i.e image pixel matrices are divided by 255 to scale between 0-1. Class labels remain unchanged.\n",
    "dataSet = dataSet.map(lambda x,y : (x / 255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "916784c4-73e8-4c69-87f7-715eedff3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numpy iterator from the dataset and splits images into batches of size 32\n",
    "# next() function retrieves the next batch of images\n",
    "iterator = dataSet.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dc8e2-234e-45b2-85a4-14980b8d2e10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# Run this cell only if dataset is scaled to range 0-1\n",
    "# Displays first 16 images from the first batch.\n",
    "nextBatch = iterator.next()\n",
    "for index in range(len(nextBatch[1][:16])):\n",
    "    plt.imshow(nextBatch[0][index])\n",
    "    plt.title(nextBatch[1][index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc145d-83b2-44e7-a4a0-c739ee482c2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterator.next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fca2ac-3cd2-4b65-abcf-b3cbac3bc174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
